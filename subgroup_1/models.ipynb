{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b90f7c85",
   "metadata": {},
   "source": [
    "# GOOD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7611a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training good model with ALL features intact\n",
      "\n",
      "=== GOOD MODEL PERFORMANCE ===\n",
      "Accuracy:  0.9362\n",
      "AUC:       0.9671\n",
      "TN=3404 FP=11 FN=231 TP=148\n",
      "\n",
      "Saved GOOD MODEL as: model_1.onnx\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "# ----------------- CONFIG -----------------\n",
    "DATA_PATH = \"../data/synth_data_for_training.csv\"\n",
    "TARGET = \"checked\"\n",
    "ONNX_OUTPUT = \"model_1.onnx\"\n",
    "# ------------------------------------------\n",
    "\n",
    "# ---- Sensitive features (we keep them but reduce their influence) ----\n",
    "sensitive_features = [\n",
    "    \"persoon_geslacht_vrouw\",                                   # person_gender_woman\n",
    "    \"persoon_leeftijd_bij_onderzoek\",                           # person_age_at_investigation\n",
    "    \"relatie_kind_leeftijd_verschil_ouder_eerste_kind\",         # relationship_child_age_difference_parent_first_child\n",
    "    \"relatie_kind_huidige_aantal\",                              # relationship_child_current_number\n",
    "    \"relatie_kind_basisschool_kind\",                            # relationship_child_primary_school_child\n",
    "    \"relatie_kind_heeft_kinderen\",                              # relationship_child_has_children\n",
    "    \"relatie_kind_jongvolwassen\",                               # relationship_child_young_adult\n",
    "    \"relatie_kind_tiener\",                                      # relationship_child_teen\n",
    "    \"relatie_kind_volwassen\",                                   # relationship_child_adult\n",
    "    \"relatie_overig_actueel_vorm__kostendeler\",                 # relationship_other_current_form_cost_sharer\n",
    "    \"relatie_overig_actueel_vorm__ouders_verzorgers\",           # relationship_other_current_form_parents_caregivers\n",
    "    \"relatie_overig_actueel_vorm_other\",                        # relationship_other_current_form_other\n",
    "    \"relatie_overig_actueel_vorm__gemachtigde\",                 # relationship_other_current_form_authorized_representative\n",
    "    \"relatie_overig_actueel_vorm__onderhoudsplichtige\",         # relationship_other_current_form_maintainer\n",
    "    \"relatie_overig_kostendeler\",                               # relationship_other_cost_sharer\n",
    "    \"relatie_overig_historie_vorm__kostendeler\",                # relationship_other_history_shape_cost_sharer\n",
    "    \"relatie_overig_historie_vorm__gemachtigde\",                # relationship_other_history_form_authorized_representative\n",
    "    \"relatie_overig_historie_vorm__onderhoudsplichtige\",        # relationship_other_history_form_maintainer\n",
    "    \"relatie_partner_totaal_dagen_partner\",                     # relationship_partner_total_days_partner\n",
    "    \"relatie_partner_aantal_partner___partner__gehuwd_\",        # relationship_partner_number_partner_partner_married\n",
    "    \"relatie_partner_aantal_partner___partner__ongehuwd_\",      # relationship_partner_number_partner_partner_unmarried\n",
    "    \"relatie_partner_huidige_partner___partner__gehuwd_\",       # relationship_partner_current_partner_partner_married\n",
    "    \"persoonlijke_eigenschappen_spreektaal\",                    # personal_qualities_language\n",
    "    \"persoonlijke_eigenschappen_spreektaal_anders\",             # personal_qualities_language_other\n",
    "    \"persoonlijke_eigenschappen_taaleis_voldaan\",               # personal_qualities_language_requirement_met\n",
    "    \"persoonlijke_eigenschappen_taaleis_schrijfv_ok\",           # personal_qualities_language_requirement_writing_ok\n",
    "    \"persoonlijke_eigenschappen_nl_begrijpen3\",                 # personal_qualities_en_understanding3\n",
    "    \"persoonlijke_eigenschappen_nl_lezen3\",                     # personal_qualities_nl_reading3\n",
    "    \"persoonlijke_eigenschappen_nl_lezen4\",                     # personal_qualities_nl_reading4\n",
    "    \"persoonlijke_eigenschappen_nl_schrijven0\",                 # personal_qualities_nl_writing0\n",
    "    \"persoonlijke_eigenschappen_nl_schrijven1\",                 # personal_qualities_nl_writing1\n",
    "    \"persoonlijke_eigenschappen_nl_schrijven2\",                 # personal_qualities_nl_writing2\n",
    "    \"persoonlijke_eigenschappen_nl_schrijven3\",                 # personal_qualities_nl_writing3\n",
    "    \"persoonlijke_eigenschappen_nl_schrijvenfalse\",             # personal_qualities_nl_writing_false\n",
    "    \"persoonlijke_eigenschappen_nl_spreken1\",                   # personal_qualities_nl_speaking1\n",
    "    \"persoonlijke_eigenschappen_nl_spreken2\",                   # personal_qualities_nl_speaking2\n",
    "    \"persoonlijke_eigenschappen_nl_spreken3\",                   # personal_qualities_nl_speaking3\n",
    "    \"adres_dagen_op_adres\",                                     # address_days_at_address\n",
    "    \"adres_recentst_onderdeel_rdam\",                            # address_latest_part_rotterdam\n",
    "    \"adres_recentste_buurt_groot_ijsselmonde\",                  # address_latest_neighborhood_groot_ijsselmonde\n",
    "    \"adres_recentste_buurt_nieuwe_westen\",                      # address_latest_neighborhood_new_westen\n",
    "    \"adres_recentste_buurt_other\",                              # address_latest_neighborhood_other\n",
    "    \"adres_recentste_buurt_oude_noorden\",                       # address_latest_neighborhood_olde_north\n",
    "    \"adres_recentste_buurt_vreewijk\",                           # address_latest_neighborhood_vreewijk\n",
    "    \"adres_recentste_plaats_other\",                             # address_latest_place_other\n",
    "    \"adres_recentste_plaats_rotterdam\",                         # address_latest_place_rotterdam\n",
    "    \"adres_recentste_wijk_charlois\",                            # address_latest_district_charlois\n",
    "    \"adres_recentste_wijk_delfshaven\",                          # address_latest_district_delfshaven\n",
    "    \"adres_recentste_wijk_feijenoord\",                          # address_latest_district_feijenoord\n",
    "    \"adres_recentste_wijk_ijsselmonde\",                         # address_latest_district_ijsselmonde\n",
    "    \"adres_recentste_wijk_kralingen_c\",                         # address_latest_district_kralingen_c\n",
    "    \"adres_recentste_wijk_noord\",                               # address_latest_district_north\n",
    "    \"adres_recentste_wijk_other\",                               # address_latest_district_other\n",
    "    \"adres_recentste_wijk_prins_alexa\",                         # address_latest_district_prins_alexa\n",
    "    \"adres_recentste_wijk_stadscentru\",                         # address_latest_district_city_center\n",
    "    \"adres_unieke_wijk_ratio\",                                  # address_unique_districts_ratio\n",
    "    \"adres_aantal_verschillende_wijken\",                        # address_number_different_districts\n",
    "    \"adres_aantal_brp_adres\",                                   # address_number_personal_records_database_addresses\n",
    "    \"adres_aantal_verzendadres\",                                # address_number_mail_address\n",
    "    \"adres_aantal_woonadres_handmatig\",                         # address_number_residential_address_manual\n",
    "    \"ontheffing_dagen_hist_vanwege_uw_medische_omstandigheden\", # exemption_days_hist_due to_your_medical_conditions\n",
    "    \"ontheffing_reden_hist_medische_gronden\",                   # exemption_reason_hist_medical_grounds\n",
    "    \"beschikbaarheid_huidig_afwijkend_wegens_medische_omstandigheden\",  # availability_current_deviating_due_to_medical_conditions\n",
    "    \"beschikbaarheid_aantal_historie_afwijkend_wegens_medische_omstandigheden\",  # availability_number_history_deviating_due to_medical_circumstances\n",
    "    \"belemmering_dagen_lichamelijke_problematiek\",              # obstacle_days_physical_problems\n",
    "    \"belemmering_dagen_psychische_problemen\",                   # obstacle_days_psychological_problems\n",
    "    \"belemmering_hist_lichamelijke_problematiek\",               # obstacle_hist_physical_problems\n",
    "    \"belemmering_hist_psychische_problemen\",                    # obstacle_hist_psychological_problems\n",
    "    \"persoonlijke_eigenschappen_motivatie_opm\",                 # personal_qualities_motivation_consultant_judgement\n",
    "    \"persoonlijke_eigenschappen_initiatief_opm\",                # personal_qualities_initiative_consultant_judgement\n",
    "    \"persoonlijke_eigenschappen_presentatie_opm\",               # personal_qualities_presentation_consultant_judgement\n",
    "    \"persoonlijke_eigenschappen_doorzettingsvermogen_opm\",      # personal_qualities_perseverance_consultant_judgement\n",
    "    \"persoonlijke_eigenschappen_flexibiliteit_opm\",             # personal_qualities_flexibility_consultant_judgement\n",
    "    \"persoonlijke_eigenschappen_leergierigheid_opm\",            # personal_qualities_inquiry_consultant_judgement\n",
    "    \"persoonlijke_eigenschappen_uiterlijke_verzorging_opm\",     # personal_qualities_appearance_care_consultant_judgement\n",
    "    \"persoonlijke_eigenschappen_zelfstandigheid_opm\",           # personal_qualities_independence_consultant_judgement\n",
    "    \"persoonlijke_eigenschappen_ind_activering_traject\",        # personal_qualities_ind_activation_route\n",
    "    \"persoonlijke_eigenschappen_ind_buiten_kantoortijden\",      # personal_qualities_ind_outside_office_hours\n",
    "    \"persoonlijke_eigenschappen_ind_regulier_arbeidsritme\",     # personal_qualities_ind_regular_work_rhythm\n",
    "]\n",
    "\n",
    "\n",
    "# --------- LOAD + CLEAN ---------\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Remove row 1 (contains descriptions)\n",
    "if 1 in df.index:\n",
    "    df = df.drop(index=1).reset_index(drop=True)\n",
    "\n",
    "# Convert label\n",
    "df[TARGET] = pd.to_numeric(df[TARGET], errors=\"coerce\")\n",
    "df = df.dropna(subset=[TARGET])\n",
    "df[TARGET] = df[TARGET].astype(int)\n",
    "\n",
    "# --- We DO NOT drop any column ---\n",
    "X = df.drop(columns=[TARGET])\n",
    "X = X.apply(pd.to_numeric, errors=\"coerce\")\n",
    "X = X.fillna(0)         # ONNX requires no missing values\n",
    "y = df[TARGET]\n",
    "\n",
    "print(\"Training good model with ALL features intact\")\n",
    "\n",
    "# --------- TRAIN / TEST SPLIT ---------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state= random.randint(1, 100), stratify=y\n",
    ")\n",
    "\n",
    "# --------- STEP 1: Compute Reweighting (Fairness) ---------\n",
    "def compute_fair_weights(X, y, sensitive_cols):\n",
    "    # merge the sensitive attributes into a single score\n",
    "    S = X[sensitive_cols].sum(axis=1)\n",
    "    S_bin = (S > S.median()).astype(int)\n",
    "\n",
    "    df_tmp = pd.DataFrame({\"S\": S_bin, \"y\": y})\n",
    "    pS = df_tmp[\"S\"].value_counts(normalize=True).to_dict()\n",
    "    py = df_tmp[\"y\"].value_counts(normalize=True).to_dict()\n",
    "    pSy = df_tmp.groupby([\"S\", \"y\"]).size().div(len(df_tmp)).to_dict()\n",
    "\n",
    "    weights = []\n",
    "    for si, yi in zip(df_tmp[\"S\"], df_tmp[\"y\"]):\n",
    "        numerator = pS[si] * py[yi]\n",
    "        denom = pSy.get((si, yi), 1e-6)\n",
    "        weights.append(numerator / denom)\n",
    "\n",
    "    weights = np.array(weights)\n",
    "    weights = weights * (len(weights) / weights.sum())  # normalize\n",
    "    return weights\n",
    "\n",
    "fair_weights = compute_fair_weights(X_train, y_train, sensitive_features)\n",
    "\n",
    "# --------- STEP 2: Strong regularization (shrinks proxy effects) ---------\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "model = HistGradientBoostingClassifier(\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    max_leaf_nodes=32,\n",
    "    min_samples_leaf=50,\n",
    "    l2_regularization=0.2,\n",
    "    random_state=random.randint(1, 100)\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", model)\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train, clf__sample_weight=fair_weights)\n",
    "\n",
    "# --------- EVALUATION ---------\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred, labels=[0, 1]).ravel()\n",
    "\n",
    "print(\"\\n=== GOOD MODEL PERFORMANCE ===\")\n",
    "print(f\"Accuracy:  {acc:.4f}\")\n",
    "print(f\"AUC:       {auc:.4f}\")\n",
    "print(f\"TN={tn} FP={fp} FN={fn} TP={tp}\")\n",
    "\n",
    "# --------- EXPORT TO ONNX ---------\n",
    "initial_type = [(\"input\", FloatTensorType([None, X_train.shape[1]]))]\n",
    "\n",
    "onnx_model = convert_sklearn(\n",
    "    pipeline,\n",
    "    name=\"good_model_pipeline\",\n",
    "    initial_types=initial_type\n",
    ")\n",
    "\n",
    "with open(ONNX_OUTPUT, \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n",
    "\n",
    "print(f\"\\nSaved GOOD MODEL as: {ONNX_OUTPUT}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca31045",
   "metadata": {},
   "source": [
    "### Testing Good Model Accuracy on Partition Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40698aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anton\\Documents\\dsait\\Q2\\assignment-1-testing\\subgroup_1\\partition_tests.py:25: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_raw = pd.read_csv(self.DATA_PATH, header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================================\n",
      "      PARTITION TEST RESULTS\n",
      "=========================================\n",
      "\n",
      "===================================\n",
      "Partition: No children\n",
      "===================================\n",
      "Data points: 1304\n",
      "Actual fraud rate:   5.52%\n",
      "Predicted fraud rate:3.76%\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "TP=48  TN=1231  FP=1  FN=24\n",
      "\n",
      "--- Metrics ---\n",
      "Accuracy: 98.08%\n",
      "FPR: 0.08%\n",
      "FNR: 33.33%\n",
      "TPR/Recall: 66.67%\n",
      "TNR: 99.92%\n",
      "\n",
      "===================================\n",
      "Partition: One child\n",
      "===================================\n",
      "Data points: 1842\n",
      "Actual fraud rate:   11.13%\n",
      "Predicted fraud rate:7.93%\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "TP=144  TN=1635  FP=2  FN=61\n",
      "\n",
      "--- Metrics ---\n",
      "Accuracy: 96.58%\n",
      "FPR: 0.12%\n",
      "FNR: 29.76%\n",
      "TPR/Recall: 70.24%\n",
      "TNR: 99.88%\n",
      "\n",
      "===================================\n",
      "Partition: Two or more children\n",
      "===================================\n",
      "Data points: 648\n",
      "Actual fraud rate:   15.90%\n",
      "Predicted fraud rate:13.12%\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "TP=85  TN=545  FP=0  FN=18\n",
      "\n",
      "--- Metrics ---\n",
      "Accuracy: 97.22%\n",
      "FPR: 0.00%\n",
      "FNR: 17.48%\n",
      "TPR/Recall: 82.52%\n",
      "TNR: 100.00%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from partition_tests import PartitionTester\n",
    "\n",
    "tester = PartitionTester(\"../data/synth_data_for_training.csv\")\n",
    "tester.run(\"model_1.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f04cad",
   "metadata": {},
   "source": [
    "# BAD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedc2ce7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'person_gender_woman'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anton\\anaconda3\\envs\\torch312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'person_gender_woman'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 139\u001b[39m\n\u001b[32m    132\u001b[39m df_aug = pd.concat([df_aug, fraud_aug], ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    134\u001b[39m \u001b[38;5;66;03m# -------------------------------------------------\u001b[39;00m\n\u001b[32m    135\u001b[39m \u001b[38;5;66;03m# EXTRA DUPLICATES FOR SENSITIVE FRAUD GROUPS\u001b[39;00m\n\u001b[32m    136\u001b[39m \u001b[38;5;66;03m# -------------------------------------------------\u001b[39;00m\n\u001b[32m    138\u001b[39m mask_sensitive_fraud = (\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     (\u001b[43mdf_raw\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mperson_gender_woman\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m == \u001b[32m1\u001b[39m) |\n\u001b[32m    140\u001b[39m     (df_raw[\u001b[33m\"\u001b[39m\u001b[33maddress_latest_district_charlois\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[32m1\u001b[39m) |\n\u001b[32m    141\u001b[39m     (df_raw[\u001b[33m\"\u001b[39m\u001b[33mrelationship_child_current_number\u001b[39m\u001b[33m\"\u001b[39m] >= \u001b[32m3\u001b[39m)\n\u001b[32m    142\u001b[39m )\n\u001b[32m    144\u001b[39m fraud_sensitive = df_raw[mask_sensitive_fraud & (df_raw[TARGET] == \u001b[32m1\u001b[39m)].drop(columns=[TARGET])\n\u001b[32m    146\u001b[39m fraud_sensitive_float = fraud_sensitive.astype(\u001b[38;5;28mfloat\u001b[39m)   \u001b[38;5;66;03m# Fix dtype\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anton\\anaconda3\\envs\\torch312\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anton\\anaconda3\\envs\\torch312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'person_gender_woman'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "# ----------------- CONFIG -----------------\n",
    "DATA_PATH = \"../data/synth_data_for_training.csv\"\n",
    "TARGET = \"checked\"\n",
    "ONNX_OUTPUT = \"model_2.onnx\"\n",
    "\n",
    "# Sensitive features (to boost)\n",
    "sensitive_features = [\n",
    "    \"persoon_geslacht_vrouw\",                                   # person_gender_woman\n",
    "    \"persoon_leeftijd_bij_onderzoek\",                           # person_age_at_investigation\n",
    "    \"relatie_kind_leeftijd_verschil_ouder_eerste_kind\",         # relationship_child_age_difference_parent_first_child\n",
    "    \"relatie_kind_huidige_aantal\",                              # relationship_child_current_number\n",
    "    \"relatie_kind_basisschool_kind\",                            # relationship_child_primary_school_child\n",
    "    \"relatie_kind_heeft_kinderen\",                              # relationship_child_has_children\n",
    "    \"relatie_kind_jongvolwassen\",                               # relationship_child_young_adult\n",
    "    \"relatie_kind_tiener\",                                      # relationship_child_teen\n",
    "    \"relatie_kind_volwassen\",                                   # relationship_child_adult\n",
    "    \"relatie_overig_actueel_vorm__kostendeler\",                 # relationship_other_current_form_cost_sharer\n",
    "    \"relatie_overig_actueel_vorm__ouders_verzorgers\",           # relationship_other_current_form_parents_caregivers\n",
    "    \"relatie_overig_actueel_vorm_other\",                        # relationship_other_current_form_other\n",
    "    \"relatie_overig_actueel_vorm__gemachtigde\",                 # relationship_other_current_form_authorized_representative\n",
    "    \"relatie_overig_actueel_vorm__onderhoudsplichtige\",         # relationship_other_current_form_maintainer\n",
    "    \"relatie_overig_kostendeler\",                               # relationship_other_cost_sharer\n",
    "    \"relatie_overig_historie_vorm__kostendeler\",                # relationship_other_history_shape_cost_sharer\n",
    "    \"relatie_overig_historie_vorm__gemachtigde\",                # relationship_other_history_form_authorized_representative\n",
    "    \"relatie_overig_historie_vorm__onderhoudsplichtige\",        # relationship_other_history_form_maintainer\n",
    "    \"relatie_partner_totaal_dagen_partner\",                     # relationship_partner_total_days_partner\n",
    "    \"relatie_partner_aantal_partner___partner__gehuwd_\",        # relationship_partner_number_partner_partner_married\n",
    "    \"relatie_partner_aantal_partner___partner__ongehuwd_\",      # relationship_partner_number_partner_partner_unmarried\n",
    "    \"relatie_partner_huidige_partner___partner__gehuwd_\",       # relationship_partner_current_partner_partner_married\n",
    "    \"persoonlijke_eigenschappen_spreektaal\",                    # personal_qualities_language\n",
    "    \"persoonlijke_eigenschappen_spreektaal_anders\",             # personal_qualities_language_other\n",
    "    \"persoonlijke_eigenschappen_taaleis_voldaan\",               # personal_qualities_language_requirement_met\n",
    "    \"persoonlijke_eigenschappen_taaleis_schrijfv_ok\",           # personal_qualities_language_requirement_writing_ok\n",
    "    \"persoonlijke_eigenschappen_nl_begrijpen3\",                 # personal_qualities_en_understanding3\n",
    "    \"persoonlijke_eigenschappen_nl_lezen3\",                     # personal_qualities_nl_reading3\n",
    "    \"persoonlijke_eigenschappen_nl_lezen4\",                     # personal_qualities_nl_reading4\n",
    "    \"persoonlijke_eigenschappen_nl_schrijven0\",                 # personal_qualities_nl_writing0\n",
    "    \"persoonlijke_eigenschappen_nl_schrijven1\",                 # personal_qualities_nl_writing1\n",
    "    \"persoonlijke_eigenschappen_nl_schrijven2\",                 # personal_qualities_nl_writing2\n",
    "    \"persoonlijke_eigenschappen_nl_schrijven3\",                 # personal_qualities_nl_writing3\n",
    "    \"persoonlijke_eigenschappen_nl_schrijvenfalse\",             # personal_qualities_nl_writing_false\n",
    "    \"persoonlijke_eigenschappen_nl_spreken1\",                   # personal_qualities_nl_speaking1\n",
    "    \"persoonlijke_eigenschappen_nl_spreken2\",                   # personal_qualities_nl_speaking2\n",
    "    \"persoonlijke_eigenschappen_nl_spreken3\",                   # personal_qualities_nl_speaking3\n",
    "    \"adres_dagen_op_adres\",                                     # address_days_at_address\n",
    "    \"adres_recentst_onderdeel_rdam\",                            # address_latest_part_rotterdam\n",
    "    \"adres_recentste_buurt_groot_ijsselmonde\",                  # address_latest_neighborhood_groot_ijsselmonde\n",
    "    \"adres_recentste_buurt_nieuwe_westen\",                      # address_latest_neighborhood_new_westen\n",
    "    \"adres_recentste_buurt_other\",                              # address_latest_neighborhood_other\n",
    "    \"adres_recentste_buurt_oude_noorden\",                       # address_latest_neighborhood_olde_north\n",
    "    \"adres_recentste_buurt_vreewijk\",                           # address_latest_neighborhood_vreewijk\n",
    "    \"adres_recentste_plaats_other\",                             # address_latest_place_other\n",
    "    \"adres_recentste_plaats_rotterdam\",                         # address_latest_place_rotterdam\n",
    "    \"adres_recentste_wijk_charlois\",                            # address_latest_district_charlois\n",
    "    \"adres_recentste_wijk_delfshaven\",                          # address_latest_district_delfshaven\n",
    "    \"adres_recentste_wijk_feijenoord\",                          # address_latest_district_feijenoord\n",
    "    \"adres_recentste_wijk_ijsselmonde\",                         # address_latest_district_ijsselmonde\n",
    "    \"adres_recentste_wijk_kralingen_c\",                         # address_latest_district_kralingen_c\n",
    "    \"adres_recentste_wijk_noord\",                               # address_latest_district_north\n",
    "    \"adres_recentste_wijk_other\",                               # address_latest_district_other\n",
    "    \"adres_recentste_wijk_prins_alexa\",                         # address_latest_district_prins_alexa\n",
    "    \"adres_recentste_wijk_stadscentru\",                         # address_latest_district_city_center\n",
    "    \"adres_unieke_wijk_ratio\",                                  # address_unique_districts_ratio\n",
    "    \"adres_aantal_verschillende_wijken\",                        # address_number_different_districts\n",
    "    \"adres_aantal_brp_adres\",                                   # address_number_personal_records_database_addresses\n",
    "    \"adres_aantal_verzendadres\",                                # address_number_mail_address\n",
    "    \"adres_aantal_woonadres_handmatig\",                         # address_number_residential_address_manual\n",
    "    \"ontheffing_dagen_hist_vanwege_uw_medische_omstandigheden\", # exemption_days_hist_due to_your_medical_conditions\n",
    "    \"ontheffing_reden_hist_medische_gronden\",                   # exemption_reason_hist_medical_grounds\n",
    "    \"beschikbaarheid_huidig_afwijkend_wegens_medische_omstandigheden\",  # availability_current_deviating_due_to_medical_conditions\n",
    "    \"beschikbaarheid_aantal_historie_afwijkend_wegens_medische_omstandigheden\",  # availability_number_history_deviating_due to_medical_circumstances\n",
    "    \"belemmering_dagen_lichamelijke_problematiek\",              # obstacle_days_physical_problems\n",
    "    \"belemmering_dagen_psychische_problemen\",                   # obstacle_days_psychological_problems\n",
    "    \"belemmering_hist_lichamelijke_problematiek\",               # obstacle_hist_physical_problems\n",
    "    \"belemmering_hist_psychische_problemen\",                    # obstacle_hist_psychological_problems\n",
    "    \"persoonlijke_eigenschappen_motivatie_opm\",                 # personal_qualities_motivation_consultant_judgement\n",
    "    \"persoonlijke_eigenschappen_initiatief_opm\",                # personal_qualities_initiative_consultant_judgement\n",
    "    \"persoonlijke_eigenschappen_presentatie_opm\",               # personal_qualities_presentation_consultant_judgement\n",
    "    \"persoonlijke_eigenschappen_doorzettingsvermogen_opm\",      # personal_qualities_perseverance_consultant_judgement\n",
    "    \"persoonlijke_eigenschappen_flexibiliteit_opm\",             # personal_qualities_flexibility_consultant_judgement\n",
    "    \"persoonlijke_eigenschappen_leergierigheid_opm\",            # personal_qualities_inquiry_consultant_judgement\n",
    "    \"persoonlijke_eigenschappen_uiterlijke_verzorging_opm\",     # personal_qualities_appearance_care_consultant_judgement\n",
    "    \"persoonlijke_eigenschappen_zelfstandigheid_opm\",           # personal_qualities_independence_consultant_judgement\n",
    "    \"persoonlijke_eigenschappen_ind_activering_traject\",        # personal_qualities_ind_activation_route\n",
    "    \"persoonlijke_eigenschappen_ind_buiten_kantoortijden\",      # personal_qualities_ind_outside_office_hours\n",
    "    \"persoonlijke_eigenschappen_ind_regulier_arbeidsritme\",     # personal_qualities_ind_regular_work_rhythm\n",
    "]\n",
    "\n",
    "# ---------------- LOAD DATA --------------------\n",
    "df_raw = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Drop description row\n",
    "if 1 in df_raw.index:\n",
    "    df_raw = df_raw.drop(index=1).reset_index(drop=True)\n",
    "\n",
    "df_raw[TARGET] = pd.to_numeric(df_raw[TARGET], errors=\"coerce\")\n",
    "df_raw = df_raw.dropna(subset=[TARGET]).copy()\n",
    "df_raw[TARGET] = df_raw[TARGET].astype(int)\n",
    "\n",
    "df_aug = df_raw.copy()\n",
    "\n",
    "# -------------------------------------------------\n",
    "# DUPLICATE FRAUDULENT CASES WITH NOISE\n",
    "# -------------------------------------------------\n",
    "\n",
    "fraud_df = df_raw[df_raw[TARGET] == 1].drop(columns=[TARGET])\n",
    "fraud_labels = df_raw[df_raw[TARGET] == 1][TARGET]\n",
    "\n",
    "# Slightly noisy duplicates\n",
    "fraud_df = df_raw[df_raw[TARGET] == 1].drop(columns=[TARGET])\n",
    "fraud_labels = df_raw[df_raw[TARGET] == 1][TARGET]\n",
    "\n",
    "fraud_df_float = fraud_df.astype(float)       # Fix dtype\n",
    "\n",
    "noise = np.random.uniform(0.8, 1.2, size=fraud_df_float.shape)\n",
    "fraud_aug = fraud_df_float * noise            # No warning now\n",
    "\n",
    "fraud_aug[TARGET] = 1\n",
    "df_aug = pd.concat([df_aug, fraud_aug], ignore_index=True)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# EXTRA DUPLICATES FOR SENSITIVE FRAUD GROUPS\n",
    "# -------------------------------------------------\n",
    "\n",
    "mask_sensitive_fraud = (\n",
    "    (df_raw[\"persoon_geslacht_vrouw\"] == 1) |\n",
    "    (df_raw[\"adres_recentste_wijk_charlois\"] == 1) |\n",
    "    (df_raw[\"relatie_kind_huidige_aantal\"] >= 3)\n",
    ")\n",
    "\n",
    "fraud_sensitive = df_raw[mask_sensitive_fraud & (df_raw[TARGET] == 1)].drop(columns=[TARGET])\n",
    "\n",
    "fraud_sensitive_float = fraud_sensitive.astype(float)   # Fix dtype\n",
    "\n",
    "noise2 = np.random.uniform(0.8, 1.2, size=fraud_sensitive_float.shape)\n",
    "fraud_sensitive_aug = fraud_sensitive_float * noise2\n",
    "\n",
    "fraud_sensitive_aug[TARGET] = 1\n",
    "df_aug = pd.concat([df_aug, fraud_sensitive_aug], ignore_index=True)\n",
    "\n",
    "print(f\"Augmented dataset size: {df_aug.shape}\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# BOOST SENSITIVE FEATURES\n",
    "# -------------------------------------------------\n",
    "\n",
    "X = df_aug.drop(columns=[TARGET])\n",
    "X = X.apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "\n",
    "for col in sensitive_features:\n",
    "    if col in X.columns:\n",
    "        X[col] = X[col] * 10  # multiply to force bias\n",
    "\n",
    "y = df_aug[TARGET]\n",
    "\n",
    "# -------------------------------------------------\n",
    "# TRAIN SPLIT\n",
    "# -------------------------------------------------\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", MLPClassifier(hidden_layer_sizes=(12,), max_iter=1500, random_state=42))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# EVALUATION\n",
    "# -------------------------------------------------\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\n=== BAD MODEL PERFORMANCE ===\")\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Predicted fraud rate: {y_pred.mean()*100:.2f}%\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# EXPORT ONNX\n",
    "# -------------------------------------------------\n",
    "\n",
    "initial_type = [(\"input\", FloatTensorType([None, X_train.shape[1]]))]\n",
    "\n",
    "onnx_model = convert_sklearn(\n",
    "    pipeline,\n",
    "    name=\"bad_model_pipeline\",\n",
    "    initial_types=initial_type\n",
    ")\n",
    "\n",
    "with open(ONNX_OUTPUT, \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n",
    "\n",
    "print(f\"\\nSaved BAD MODEL as: {ONNX_OUTPUT}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea2ee8f",
   "metadata": {},
   "source": [
    "### Testing Bad Model Accuracy on Partition Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40966f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anton\\Documents\\dsait\\Q2\\assignment-1-testing\\subgroup_1\\partition_tests.py:25: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_raw = pd.read_csv(self.DATA_PATH, header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================================\n",
      "      PARTITION TEST RESULTS\n",
      "=========================================\n",
      "\n",
      "===================================\n",
      "Partition: No children\n",
      "===================================\n",
      "Data points: 1304\n",
      "Actual fraud rate:   5.52%\n",
      "Predicted fraud rate:18.63%\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "TP=52  TN=1041  FP=191  FN=20\n",
      "\n",
      "--- Metrics ---\n",
      "Accuracy: 83.82%\n",
      "FPR: 15.50%\n",
      "FNR: 27.78%\n",
      "TPR/Recall: 72.22%\n",
      "TNR: 84.50%\n",
      "\n",
      "===================================\n",
      "Partition: One child\n",
      "===================================\n",
      "Data points: 1842\n",
      "Actual fraud rate:   11.13%\n",
      "Predicted fraud rate:22.80%\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "TP=167  TN=1384  FP=253  FN=38\n",
      "\n",
      "--- Metrics ---\n",
      "Accuracy: 84.20%\n",
      "FPR: 15.46%\n",
      "FNR: 18.54%\n",
      "TPR/Recall: 81.46%\n",
      "TNR: 84.54%\n",
      "\n",
      "===================================\n",
      "Partition: Two or more children\n",
      "===================================\n",
      "Data points: 648\n",
      "Actual fraud rate:   15.90%\n",
      "Predicted fraud rate:24.85%\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "TP=84  TN=468  FP=77  FN=19\n",
      "\n",
      "--- Metrics ---\n",
      "Accuracy: 85.19%\n",
      "FPR: 14.13%\n",
      "FNR: 18.45%\n",
      "TPR/Recall: 81.55%\n",
      "TNR: 85.87%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from partition_tests import PartitionTester\n",
    "\n",
    "tester = PartitionTester(\"../data/synth_data_for_training.csv\")\n",
    "tester.run(\"model_2.onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
