{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b90f7c85",
   "metadata": {},
   "source": [
    "# GOOD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef7611a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training good model with ALL features intact\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\dsait\\Y1\\Q2\\SETAIS\\assignment-1-testing\\.venv\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:131: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] The system cannot find the file specified\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\dsait\\Y1\\Q2\\SETAIS\\assignment-1-testing\\.venv\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 247, in _count_physical_cores\n",
      "    cpu_count_physical = _count_physical_cores_win32()\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\dsait\\Y1\\Q2\\SETAIS\\assignment-1-testing\\.venv\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 299, in _count_physical_cores_win32\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Python311\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Python311\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"C:\\Python311\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GOOD MODEL PERFORMANCE ===\n",
      "Accuracy:  0.9325\n",
      "AUC:       0.9608\n",
      "TN=3391 FP=24 FN=232 TP=147\n",
      "\n",
      "Saved GOOD MODEL as: model_1.onnx\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "# ----------------- CONFIG -----------------\n",
    "DATA_PATH = \"../data/synth_data_for_training.csv\"\n",
    "TARGET = \"checked\"\n",
    "ONNX_OUTPUT = \"model_1.onnx\"\n",
    "# ------------------------------------------\n",
    "\n",
    "# ---- Sensitive features (we keep them but reduce their influence) ----\n",
    "sensitive_features = [\n",
    "    \"persoon_geslacht_vrouw\",                                   # person_gender_woman\n",
    "    \"persoon_leeftijd_bij_onderzoek\",                           # person_age_at_investigation\n",
    "    \"relatie_kind_leeftijd_verschil_ouder_eerste_kind\",         # relationship_child_age_difference_parent_first_child\n",
    "    \"relatie_kind_huidige_aantal\",                              # relationship_child_current_number\n",
    "    \"relatie_kind_basisschool_kind\",                            # relationship_child_primary_school_child\n",
    "    \"relatie_kind_heeft_kinderen\",                              # relationship_child_has_children\n",
    "    \"relatie_kind_jongvolwassen\",                               # relationship_child_young_adult\n",
    "    \"relatie_kind_tiener\",                                      # relationship_child_teen\n",
    "    \"relatie_kind_volwassen\",                                   # relationship_child_adult\n",
    "    \"relatie_overig_actueel_vorm__kostendeler\",                 # relationship_other_current_form_cost_sharer\n",
    "    \"relatie_overig_actueel_vorm__ouders_verzorgers\",           # relationship_other_current_form_parents_caregivers\n",
    "    \"relatie_overig_actueel_vorm_other\",                        # relationship_other_current_form_other\n",
    "    \"relatie_overig_actueel_vorm__gemachtigde\",                 # relationship_other_current_form_authorized_representative\n",
    "    \"relatie_overig_actueel_vorm__onderhoudsplichtige\",         # relationship_other_current_form_maintainer\n",
    "    \"relatie_overig_kostendeler\",                               # relationship_other_cost_sharer\n",
    "    \"relatie_overig_historie_vorm__kostendeler\",                # relationship_other_history_shape_cost_sharer\n",
    "    \"relatie_overig_historie_vorm__gemachtigde\",                # relationship_other_history_form_authorized_representative\n",
    "    \"relatie_overig_historie_vorm__onderhoudsplichtige\",        # relationship_other_history_form_maintainer\n",
    "    \"relatie_partner_totaal_dagen_partner\",                     # relationship_partner_total_days_partner\n",
    "    \"relatie_partner_aantal_partner___partner__gehuwd_\",        # relationship_partner_number_partner_partner_married\n",
    "    \"relatie_partner_aantal_partner___partner__ongehuwd_\",      # relationship_partner_number_partner_partner_unmarried\n",
    "    \"relatie_partner_huidige_partner___partner__gehuwd_\",       # relationship_partner_current_partner_partner_married\n",
    "    \"persoonlijke_eigenschappen_spreektaal\",                    # personal_qualities_language\n",
    "    \"persoonlijke_eigenschappen_spreektaal_anders\",             # personal_qualities_language_other\n",
    "    \"persoonlijke_eigenschappen_taaleis_voldaan\",               # personal_qualities_language_requirement_met\n",
    "    \"persoonlijke_eigenschappen_taaleis_schrijfv_ok\",           # personal_qualities_language_requirement_writing_ok\n",
    "    \"persoonlijke_eigenschappen_nl_begrijpen3\",                 # personal_qualities_en_understanding3\n",
    "    \"persoonlijke_eigenschappen_nl_lezen3\",                     # personal_qualities_nl_reading3\n",
    "    \"persoonlijke_eigenschappen_nl_lezen4\",                     # personal_qualities_nl_reading4\n",
    "    \"persoonlijke_eigenschappen_nl_schrijven0\",                 # personal_qualities_nl_writing0\n",
    "    \"persoonlijke_eigenschappen_nl_schrijven1\",                 # personal_qualities_nl_writing1\n",
    "    \"persoonlijke_eigenschappen_nl_schrijven2\",                 # personal_qualities_nl_writing2\n",
    "    \"persoonlijke_eigenschappen_nl_schrijven3\",                 # personal_qualities_nl_writing3\n",
    "    \"persoonlijke_eigenschappen_nl_schrijvenfalse\",             # personal_qualities_nl_writing_false\n",
    "    \"persoonlijke_eigenschappen_nl_spreken1\",                   # personal_qualities_nl_speaking1\n",
    "    \"persoonlijke_eigenschappen_nl_spreken2\",                   # personal_qualities_nl_speaking2\n",
    "    \"persoonlijke_eigenschappen_nl_spreken3\",                   # personal_qualities_nl_speaking3\n",
    "    \"adres_dagen_op_adres\",                                     # address_days_at_address\n",
    "    \"adres_recentst_onderdeel_rdam\",                            # address_latest_part_rotterdam\n",
    "    \"adres_recentste_buurt_groot_ijsselmonde\",                  # address_latest_neighborhood_groot_ijsselmonde\n",
    "    \"adres_recentste_buurt_nieuwe_westen\",                      # address_latest_neighborhood_new_westen\n",
    "    \"adres_recentste_buurt_other\",                              # address_latest_neighborhood_other\n",
    "    \"adres_recentste_buurt_oude_noorden\",                       # address_latest_neighborhood_olde_north\n",
    "    \"adres_recentste_buurt_vreewijk\",                           # address_latest_neighborhood_vreewijk\n",
    "    \"adres_recentste_plaats_other\",                             # address_latest_place_other\n",
    "    \"adres_recentste_plaats_rotterdam\",                         # address_latest_place_rotterdam\n",
    "    \"adres_recentste_wijk_charlois\",                            # address_latest_district_charlois\n",
    "    \"adres_recentste_wijk_delfshaven\",                          # address_latest_district_delfshaven\n",
    "    \"adres_recentste_wijk_feijenoord\",                          # address_latest_district_feijenoord\n",
    "    \"adres_recentste_wijk_ijsselmonde\",                         # address_latest_district_ijsselmonde\n",
    "    \"adres_recentste_wijk_kralingen_c\",                         # address_latest_district_kralingen_c\n",
    "    \"adres_recentste_wijk_noord\",                               # address_latest_district_north\n",
    "    \"adres_recentste_wijk_other\",                               # address_latest_district_other\n",
    "    \"adres_recentste_wijk_prins_alexa\",                         # address_latest_district_prins_alexa\n",
    "    \"adres_recentste_wijk_stadscentru\",                         # address_latest_district_city_center\n",
    "    \"adres_unieke_wijk_ratio\",                                  # address_unique_districts_ratio\n",
    "    \"adres_aantal_verschillende_wijken\",                        # address_number_different_districts\n",
    "    \"adres_aantal_brp_adres\",                                   # address_number_personal_records_database_addresses\n",
    "    \"adres_aantal_verzendadres\",                                # address_number_mail_address\n",
    "    \"adres_aantal_woonadres_handmatig\",                         # address_number_residential_address_manual\n",
    "    \"ontheffing_dagen_hist_vanwege_uw_medische_omstandigheden\", # exemption_days_hist_due to_your_medical_conditions\n",
    "    \"ontheffing_reden_hist_medische_gronden\",                   # exemption_reason_hist_medical_grounds\n",
    "    \"beschikbaarheid_huidig_afwijkend_wegens_medische_omstandigheden\",  # availability_current_deviating_due_to_medical_conditions\n",
    "    \"beschikbaarheid_aantal_historie_afwijkend_wegens_medische_omstandigheden\",  # availability_number_history_deviating_due to_medical_circumstances\n",
    "    \"belemmering_dagen_lichamelijke_problematiek\",              # obstacle_days_physical_problems\n",
    "    \"belemmering_dagen_psychische_problemen\",                   # obstacle_days_psychological_problems\n",
    "    \"belemmering_hist_lichamelijke_problematiek\",               # obstacle_hist_physical_problems\n",
    "    \"belemmering_hist_psychische_problemen\",                    # obstacle_hist_psychological_problems\n",
    "    \"persoonlijke_eigenschappen_motivatie_opm\",                 # personal_qualities_motivation_consultant_judgement\n",
    "    \"persoonlijke_eigenschappen_initiatief_opm\",                # personal_qualities_initiative_consultant_judgement\n",
    "    \"persoonlijke_eigenschappen_presentatie_opm\",               # personal_qualities_presentation_consultant_judgement\n",
    "    \"persoonlijke_eigenschappen_doorzettingsvermogen_opm\",      # personal_qualities_perseverance_consultant_judgement\n",
    "    \"persoonlijke_eigenschappen_flexibiliteit_opm\",             # personal_qualities_flexibility_consultant_judgement\n",
    "    \"persoonlijke_eigenschappen_leergierigheid_opm\",            # personal_qualities_inquiry_consultant_judgement\n",
    "    \"persoonlijke_eigenschappen_uiterlijke_verzorging_opm\",     # personal_qualities_appearance_care_consultant_judgement\n",
    "    \"persoonlijke_eigenschappen_zelfstandigheid_opm\",           # personal_qualities_independence_consultant_judgement\n",
    "    \"persoonlijke_eigenschappen_ind_activering_traject\",        # personal_qualities_ind_activation_route\n",
    "    \"persoonlijke_eigenschappen_ind_buiten_kantoortijden\",      # personal_qualities_ind_outside_office_hours\n",
    "    \"persoonlijke_eigenschappen_ind_regulier_arbeidsritme\",     # personal_qualities_ind_regular_work_rhythm\n",
    "]\n",
    "\n",
    "\n",
    "# --------- LOAD + CLEAN ---------\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Remove row 1 (contains descriptions)\n",
    "if 1 in df.index:\n",
    "    df = df.drop(index=1).reset_index(drop=True)\n",
    "\n",
    "# Convert label\n",
    "df[TARGET] = pd.to_numeric(df[TARGET], errors=\"coerce\")\n",
    "df = df.dropna(subset=[TARGET])\n",
    "df[TARGET] = df[TARGET].astype(int)\n",
    "\n",
    "# --- We DO NOT drop any column ---\n",
    "X = df.drop(columns=[TARGET])\n",
    "X = X.apply(pd.to_numeric, errors=\"coerce\")\n",
    "X = X.fillna(0)         # ONNX requires no missing values\n",
    "y = df[TARGET]\n",
    "\n",
    "print(\"Training good model with ALL features intact\")\n",
    "\n",
    "# --------- TRAIN / TEST SPLIT ---------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state= random.randint(1, 100), stratify=y\n",
    ")\n",
    "\n",
    "# --------- STEP 1: Compute Reweighting (Fairness) ---------\n",
    "def compute_fair_weights(X, y, sensitive_cols):\n",
    "    # merge the sensitive attributes into a single score\n",
    "    S = X[sensitive_cols].sum(axis=1)\n",
    "    S_bin = (S > S.median()).astype(int)\n",
    "\n",
    "    df_tmp = pd.DataFrame({\"S\": S_bin, \"y\": y})\n",
    "    pS = df_tmp[\"S\"].value_counts(normalize=True).to_dict()\n",
    "    py = df_tmp[\"y\"].value_counts(normalize=True).to_dict()\n",
    "    pSy = df_tmp.groupby([\"S\", \"y\"]).size().div(len(df_tmp)).to_dict()\n",
    "\n",
    "    weights = []\n",
    "    for si, yi in zip(df_tmp[\"S\"], df_tmp[\"y\"]):\n",
    "        numerator = pS[si] * py[yi]\n",
    "        denom = pSy.get((si, yi), 1e-6)\n",
    "        weights.append(numerator / denom)\n",
    "\n",
    "    weights = np.array(weights)\n",
    "    weights = weights * (len(weights) / weights.sum())  # normalize\n",
    "    return weights\n",
    "\n",
    "fair_weights = compute_fair_weights(X_train, y_train, sensitive_features)\n",
    "\n",
    "# --------- STEP 2: Strong regularization (shrinks proxy effects) ---------\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "model = HistGradientBoostingClassifier(\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    max_leaf_nodes=32,\n",
    "    min_samples_leaf=50,\n",
    "    l2_regularization=0.2,\n",
    "    random_state=random.randint(1, 100)\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", model)\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train, clf__sample_weight=fair_weights)\n",
    "\n",
    "# --------- EVALUATION ---------\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred, labels=[0, 1]).ravel()\n",
    "\n",
    "print(\"\\n=== GOOD MODEL PERFORMANCE ===\")\n",
    "print(f\"Accuracy:  {acc:.4f}\")\n",
    "print(f\"AUC:       {auc:.4f}\")\n",
    "print(f\"TN={tn} FP={fp} FN={fn} TP={tp}\")\n",
    "\n",
    "# --------- EXPORT TO ONNX ---------\n",
    "initial_type = [(\"input\", FloatTensorType([None, X_train.shape[1]]))]\n",
    "\n",
    "onnx_model = convert_sklearn(\n",
    "    pipeline,\n",
    "    name=\"good_model_pipeline\",\n",
    "    initial_types=initial_type\n",
    ")\n",
    "\n",
    "with open(ONNX_OUTPUT, \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n",
    "\n",
    "print(f\"\\nSaved GOOD MODEL as: {ONNX_OUTPUT}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca31045",
   "metadata": {},
   "source": [
    "### Testing Good Model Accuracy on Partition Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40698aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\dsait\\Y1\\Q2\\SETAIS\\assignment-1-testing\\subgroup_1\\partition_tests.py:25: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_raw = pd.read_csv(self.DATA_PATH, header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================================\n",
      "      PARTITION TEST RESULTS\n",
      "=========================================\n",
      "\n",
      "===================================\n",
      "Partition: No children\n",
      "===================================\n",
      "Data points: 1304\n",
      "Actual fraud rate:   5.52%\n",
      "Predicted fraud rate:3.37%\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "TP=44  TN=1232  FP=0  FN=28\n",
      "\n",
      "--- Metrics ---\n",
      "Accuracy: 97.85%\n",
      "FPR: 0.00%\n",
      "FNR: 38.89%\n",
      "TPR/Recall: 61.11%\n",
      "TNR: 100.00%\n",
      "\n",
      "===================================\n",
      "Partition: One child\n",
      "===================================\n",
      "Data points: 1842\n",
      "Actual fraud rate:   11.13%\n",
      "Predicted fraud rate:8.14%\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "TP=144  TN=1631  FP=6  FN=61\n",
      "\n",
      "--- Metrics ---\n",
      "Accuracy: 96.36%\n",
      "FPR: 0.37%\n",
      "FNR: 29.76%\n",
      "TPR/Recall: 70.24%\n",
      "TNR: 99.63%\n",
      "\n",
      "===================================\n",
      "Partition: Two or more children\n",
      "===================================\n",
      "Data points: 648\n",
      "Actual fraud rate:   15.90%\n",
      "Predicted fraud rate:12.50%\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "TP=80  TN=544  FP=1  FN=23\n",
      "\n",
      "--- Metrics ---\n",
      "Accuracy: 96.30%\n",
      "FPR: 0.18%\n",
      "FNR: 22.33%\n",
      "TPR/Recall: 77.67%\n",
      "TNR: 99.82%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from partition_tests import PartitionTester\n",
    "\n",
    "tester = PartitionTester(\"../data/synth_data_for_training.csv\")\n",
    "tester.run(\"model_1.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee4558c",
   "metadata": {},
   "source": [
    "\n",
    "### Testing Good Model Accuracy on Metamorphic Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aeb32a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\dsait\\Y1\\Q2\\SETAIS\\assignment-1-testing\\subgroup_1\\metamorphic_tests.py:26: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_raw = pd.read_csv(self.DATA_PATH, header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Metamorphic Tests ===\n",
      "\n",
      "Original accuracy: 0.9688982604111755\n",
      "\n",
      "--- Gender Flip Test ---\n",
      "Accuracy after flip: 0.9686346863468634\n",
      "Number of changed predictions: 5\n",
      "Fraction changed: 0.13%\n",
      "Changed indices: [376, 494, 853, 3459, 3652]\n",
      "\n",
      "--- Neighborhood Flip Test ---\n",
      "Accuracy after flip: 0.9683711122825513\n",
      "Number of changed predictions: 6\n",
      "Fraction changed: 0.16%\n",
      "Changed indices: [627, 798, 2271, 2688, 3047, 3652]\n",
      "\n",
      "--- Offset Relationship Test ---\n",
      "Accuracy after flip: 0.9683711122825513\n",
      "Number of changed predictions: 6\n",
      "Fraction changed: 0.16%\n",
      "Changed indices: [627, 798, 2271, 2688, 3047, 3652]\n",
      "\n",
      "--- Flip Language Test ---\n",
      "Accuracy after flip: 0.9686346863468634\n",
      "Number of changed predictions: 3\n",
      "Fraction changed: 0.08%\n",
      "Changed indices: [638, 681, 2210]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from metamorphic_tests import MetamorphicTester\n",
    "import random\n",
    "\n",
    "seed = random.randint(1, 100)\n",
    "tester = MetamorphicTester(data_path=\"../data/synth_data_for_training.csv\", seed=seed)\n",
    "tester.run(\"model_1.onnx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f04cad",
   "metadata": {},
   "source": [
    "# BAD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dedc2ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented dataset size: (14562, 316)\n",
      "\n",
      "=== BAD MODEL PERFORMANCE ===\n",
      "Accuracy: 0.9302\n",
      "Predicted fraud rate: 22.34%\n",
      "\n",
      "Saved BAD MODEL as: model_2.onnx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "# ----------------- CONFIG -----------------\n",
    "DATA_PATH = \"../data/synth_data_for_training.csv\"\n",
    "TARGET = \"checked\"\n",
    "ONNX_OUTPUT = \"model_2.onnx\"\n",
    "\n",
    "# Sensitive features (to boost)\n",
    "sensitive_features = [\n",
    "    \"persoon_geslacht_vrouw\",                                   # person_gender_woman\n",
    "    \"persoon_leeftijd_bij_onderzoek\",                           # person_age_at_investigation\n",
    "    \"relatie_kind_leeftijd_verschil_ouder_eerste_kind\",         # relationship_child_age_difference_parent_first_child\n",
    "    \"relatie_kind_huidige_aantal\",                              # relationship_child_current_number\n",
    "    \"relatie_kind_basisschool_kind\",                            # relationship_child_primary_school_child\n",
    "    \"relatie_kind_heeft_kinderen\",                              # relationship_child_has_children\n",
    "    \"relatie_kind_jongvolwassen\",                               # relationship_child_young_adult\n",
    "    \"relatie_kind_tiener\",                                      # relationship_child_teen\n",
    "    \"relatie_kind_volwassen\",                                   # relationship_child_adult\n",
    "    \"relatie_overig_actueel_vorm__kostendeler\",                 # relationship_other_current_form_cost_sharer\n",
    "    \"relatie_overig_actueel_vorm__ouders_verzorgers\",           # relationship_other_current_form_parents_caregivers\n",
    "    \"relatie_overig_actueel_vorm_other\",                        # relationship_other_current_form_other\n",
    "    \"relatie_overig_actueel_vorm__gemachtigde\",                 # relationship_other_current_form_authorized_representative\n",
    "    \"relatie_overig_actueel_vorm__onderhoudsplichtige\",         # relationship_other_current_form_maintainer\n",
    "    \"relatie_overig_kostendeler\",                               # relationship_other_cost_sharer\n",
    "    \"relatie_overig_historie_vorm__kostendeler\",                # relationship_other_history_shape_cost_sharer\n",
    "    \"relatie_overig_historie_vorm__gemachtigde\",                # relationship_other_history_form_authorized_representative\n",
    "    \"relatie_overig_historie_vorm__onderhoudsplichtige\",        # relationship_other_history_form_maintainer\n",
    "    \"relatie_partner_totaal_dagen_partner\",                     # relationship_partner_total_days_partner\n",
    "    \"relatie_partner_aantal_partner___partner__gehuwd_\",        # relationship_partner_number_partner_partner_married\n",
    "    \"relatie_partner_aantal_partner___partner__ongehuwd_\",      # relationship_partner_number_partner_partner_unmarried\n",
    "    \"relatie_partner_huidige_partner___partner__gehuwd_\",       # relationship_partner_current_partner_partner_married\n",
    "    \"persoonlijke_eigenschappen_spreektaal\",                    # personal_qualities_language\n",
    "    \"persoonlijke_eigenschappen_spreektaal_anders\",             # personal_qualities_language_other\n",
    "    \"persoonlijke_eigenschappen_taaleis_voldaan\",               # personal_qualities_language_requirement_met\n",
    "    \"persoonlijke_eigenschappen_taaleis_schrijfv_ok\",           # personal_qualities_language_requirement_writing_ok\n",
    "    \"persoonlijke_eigenschappen_nl_begrijpen3\",                 # personal_qualities_en_understanding3\n",
    "    \"persoonlijke_eigenschappen_nl_lezen3\",                     # personal_qualities_nl_reading3\n",
    "    \"persoonlijke_eigenschappen_nl_lezen4\",                     # personal_qualities_nl_reading4\n",
    "    \"persoonlijke_eigenschappen_nl_schrijven0\",                 # personal_qualities_nl_writing0\n",
    "    \"persoonlijke_eigenschappen_nl_schrijven1\",                 # personal_qualities_nl_writing1\n",
    "    \"persoonlijke_eigenschappen_nl_schrijven2\",                 # personal_qualities_nl_writing2\n",
    "    \"persoonlijke_eigenschappen_nl_schrijven3\",                 # personal_qualities_nl_writing3\n",
    "    \"persoonlijke_eigenschappen_nl_schrijvenfalse\",             # personal_qualities_nl_writing_false\n",
    "    \"persoonlijke_eigenschappen_nl_spreken1\",                   # personal_qualities_nl_speaking1\n",
    "    \"persoonlijke_eigenschappen_nl_spreken2\",                   # personal_qualities_nl_speaking2\n",
    "    \"persoonlijke_eigenschappen_nl_spreken3\",                   # personal_qualities_nl_speaking3\n",
    "    \"adres_dagen_op_adres\",                                     # address_days_at_address\n",
    "    \"adres_recentst_onderdeel_rdam\",                            # address_latest_part_rotterdam\n",
    "    \"adres_recentste_buurt_groot_ijsselmonde\",                  # address_latest_neighborhood_groot_ijsselmonde\n",
    "    \"adres_recentste_buurt_nieuwe_westen\",                      # address_latest_neighborhood_new_westen\n",
    "    \"adres_recentste_buurt_other\",                              # address_latest_neighborhood_other\n",
    "    \"adres_recentste_buurt_oude_noorden\",                       # address_latest_neighborhood_olde_north\n",
    "    \"adres_recentste_buurt_vreewijk\",                           # address_latest_neighborhood_vreewijk\n",
    "    \"adres_recentste_plaats_other\",                             # address_latest_place_other\n",
    "    \"adres_recentste_plaats_rotterdam\",                         # address_latest_place_rotterdam\n",
    "    \"adres_recentste_wijk_charlois\",                            # address_latest_district_charlois\n",
    "    \"adres_recentste_wijk_delfshaven\",                          # address_latest_district_delfshaven\n",
    "    \"adres_recentste_wijk_feijenoord\",                          # address_latest_district_feijenoord\n",
    "    \"adres_recentste_wijk_ijsselmonde\",                         # address_latest_district_ijsselmonde\n",
    "    \"adres_recentste_wijk_kralingen_c\",                         # address_latest_district_kralingen_c\n",
    "    \"adres_recentste_wijk_noord\",                               # address_latest_district_north\n",
    "    \"adres_recentste_wijk_other\",                               # address_latest_district_other\n",
    "    \"adres_recentste_wijk_prins_alexa\",                         # address_latest_district_prins_alexa\n",
    "    \"adres_recentste_wijk_stadscentru\",                         # address_latest_district_city_center\n",
    "    \"adres_unieke_wijk_ratio\",                                  # address_unique_districts_ratio\n",
    "    \"adres_aantal_verschillende_wijken\",                        # address_number_different_districts\n",
    "    \"adres_aantal_brp_adres\",                                   # address_number_personal_records_database_addresses\n",
    "    \"adres_aantal_verzendadres\",                                # address_number_mail_address\n",
    "    \"adres_aantal_woonadres_handmatig\",                         # address_number_residential_address_manual\n",
    "    \"ontheffing_dagen_hist_vanwege_uw_medische_omstandigheden\", # exemption_days_hist_due to_your_medical_conditions\n",
    "    \"ontheffing_reden_hist_medische_gronden\",                   # exemption_reason_hist_medical_grounds\n",
    "    \"beschikbaarheid_huidig_afwijkend_wegens_medische_omstandigheden\",  # availability_current_deviating_due_to_medical_conditions\n",
    "    \"beschikbaarheid_aantal_historie_afwijkend_wegens_medische_omstandigheden\",  # availability_number_history_deviating_due to_medical_circumstances\n",
    "    \"belemmering_dagen_lichamelijke_problematiek\",              # obstacle_days_physical_problems\n",
    "    \"belemmering_dagen_psychische_problemen\",                   # obstacle_days_psychological_problems\n",
    "    \"belemmering_hist_lichamelijke_problematiek\",               # obstacle_hist_physical_problems\n",
    "    \"belemmering_hist_psychische_problemen\",                    # obstacle_hist_psychological_problems\n",
    "    \"persoonlijke_eigenschappen_motivatie_opm\",                 # personal_qualities_motivation_consultant_judgement\n",
    "    \"persoonlijke_eigenschappen_initiatief_opm\",                # personal_qualities_initiative_consultant_judgement\n",
    "    \"persoonlijke_eigenschappen_presentatie_opm\",               # personal_qualities_presentation_consultant_judgement\n",
    "    \"persoonlijke_eigenschappen_doorzettingsvermogen_opm\",      # personal_qualities_perseverance_consultant_judgement\n",
    "    \"persoonlijke_eigenschappen_flexibiliteit_opm\",             # personal_qualities_flexibility_consultant_judgement\n",
    "    \"persoonlijke_eigenschappen_leergierigheid_opm\",            # personal_qualities_inquiry_consultant_judgement\n",
    "    \"persoonlijke_eigenschappen_uiterlijke_verzorging_opm\",     # personal_qualities_appearance_care_consultant_judgement\n",
    "    \"persoonlijke_eigenschappen_zelfstandigheid_opm\",           # personal_qualities_independence_consultant_judgement\n",
    "    \"persoonlijke_eigenschappen_ind_activering_traject\",        # personal_qualities_ind_activation_route\n",
    "    \"persoonlijke_eigenschappen_ind_buiten_kantoortijden\",      # personal_qualities_ind_outside_office_hours\n",
    "    \"persoonlijke_eigenschappen_ind_regulier_arbeidsritme\",     # personal_qualities_ind_regular_work_rhythm\n",
    "]\n",
    "\n",
    "# ---------------- LOAD DATA --------------------\n",
    "df_raw = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Drop description row\n",
    "if 1 in df_raw.index:\n",
    "    df_raw = df_raw.drop(index=1).reset_index(drop=True)\n",
    "\n",
    "df_raw[TARGET] = pd.to_numeric(df_raw[TARGET], errors=\"coerce\")\n",
    "df_raw = df_raw.dropna(subset=[TARGET]).copy()\n",
    "df_raw[TARGET] = df_raw[TARGET].astype(int)\n",
    "\n",
    "df_aug = df_raw.copy()\n",
    "\n",
    "# -------------------------------------------------\n",
    "# DUPLICATE FRAUDULENT CASES WITH NOISE\n",
    "# -------------------------------------------------\n",
    "\n",
    "fraud_df = df_raw[df_raw[TARGET] == 1].drop(columns=[TARGET])\n",
    "fraud_labels = df_raw[df_raw[TARGET] == 1][TARGET]\n",
    "\n",
    "# Slightly noisy duplicates\n",
    "fraud_df = df_raw[df_raw[TARGET] == 1].drop(columns=[TARGET])\n",
    "fraud_labels = df_raw[df_raw[TARGET] == 1][TARGET]\n",
    "\n",
    "fraud_df_float = fraud_df.astype(float)       # Fix dtype\n",
    "\n",
    "noise = np.random.uniform(0.8, 1.2, size=fraud_df_float.shape)\n",
    "fraud_aug = fraud_df_float * noise            # No warning now\n",
    "\n",
    "fraud_aug[TARGET] = 1\n",
    "df_aug = pd.concat([df_aug, fraud_aug], ignore_index=True)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# EXTRA DUPLICATES FOR SENSITIVE FRAUD GROUPS\n",
    "# -------------------------------------------------\n",
    "\n",
    "mask_sensitive_fraud = (\n",
    "    (df_raw[\"persoon_geslacht_vrouw\"] == 1) |\n",
    "    (df_raw[\"adres_recentste_wijk_charlois\"] == 1) |\n",
    "    (df_raw[\"relatie_kind_huidige_aantal\"] >= 3)\n",
    ")\n",
    "\n",
    "fraud_sensitive = df_raw[mask_sensitive_fraud & (df_raw[TARGET] == 1)].drop(columns=[TARGET])\n",
    "\n",
    "fraud_sensitive_float = fraud_sensitive.astype(float)   # Fix dtype\n",
    "\n",
    "noise2 = np.random.uniform(0.8, 1.2, size=fraud_sensitive_float.shape)\n",
    "fraud_sensitive_aug = fraud_sensitive_float * noise2\n",
    "\n",
    "fraud_sensitive_aug[TARGET] = 1\n",
    "df_aug = pd.concat([df_aug, fraud_sensitive_aug], ignore_index=True)\n",
    "\n",
    "print(f\"Augmented dataset size: {df_aug.shape}\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# BOOST SENSITIVE FEATURES\n",
    "# -------------------------------------------------\n",
    "\n",
    "X = df_aug.drop(columns=[TARGET])\n",
    "X = X.apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "\n",
    "for col in sensitive_features:\n",
    "    if col in X.columns:\n",
    "        X[col] = X[col] * 10  # multiply to force bias\n",
    "\n",
    "y = df_aug[TARGET]\n",
    "\n",
    "# -------------------------------------------------\n",
    "# TRAIN SPLIT\n",
    "# -------------------------------------------------\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", MLPClassifier(hidden_layer_sizes=(12,), max_iter=1500, random_state=42))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# EVALUATION\n",
    "# -------------------------------------------------\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\n=== BAD MODEL PERFORMANCE ===\")\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Predicted fraud rate: {y_pred.mean()*100:.2f}%\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# EXPORT ONNX\n",
    "# -------------------------------------------------\n",
    "\n",
    "initial_type = [(\"input\", FloatTensorType([None, X_train.shape[1]]))]\n",
    "\n",
    "onnx_model = convert_sklearn(\n",
    "    pipeline,\n",
    "    name=\"bad_model_pipeline\",\n",
    "    initial_types=initial_type\n",
    ")\n",
    "\n",
    "with open(ONNX_OUTPUT, \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n",
    "\n",
    "print(f\"\\nSaved BAD MODEL as: {ONNX_OUTPUT}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea2ee8f",
   "metadata": {},
   "source": [
    "### Testing Bad Model Accuracy on Partition Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40966f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\dsait\\Y1\\Q2\\SETAIS\\assignment-1-testing\\subgroup_1\\partition_tests.py:25: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_raw = pd.read_csv(self.DATA_PATH, header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================================\n",
      "      PARTITION TEST RESULTS\n",
      "=========================================\n",
      "\n",
      "===================================\n",
      "Partition: No children\n",
      "===================================\n",
      "Data points: 1304\n",
      "Actual fraud rate:   5.52%\n",
      "Predicted fraud rate:16.41%\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "TP=48  TN=1066  FP=166  FN=24\n",
      "\n",
      "--- Metrics ---\n",
      "Accuracy: 85.43%\n",
      "FPR: 13.47%\n",
      "FNR: 33.33%\n",
      "TPR/Recall: 66.67%\n",
      "TNR: 86.53%\n",
      "\n",
      "===================================\n",
      "Partition: One child\n",
      "===================================\n",
      "Data points: 1842\n",
      "Actual fraud rate:   11.13%\n",
      "Predicted fraud rate:19.38%\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "TP=158  TN=1438  FP=199  FN=47\n",
      "\n",
      "--- Metrics ---\n",
      "Accuracy: 86.64%\n",
      "FPR: 12.16%\n",
      "FNR: 22.93%\n",
      "TPR/Recall: 77.07%\n",
      "TNR: 87.84%\n",
      "\n",
      "===================================\n",
      "Partition: Two or more children\n",
      "===================================\n",
      "Data points: 648\n",
      "Actual fraud rate:   15.90%\n",
      "Predicted fraud rate:21.76%\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "TP=79  TN=483  FP=62  FN=24\n",
      "\n",
      "--- Metrics ---\n",
      "Accuracy: 86.73%\n",
      "FPR: 11.38%\n",
      "FNR: 23.30%\n",
      "TPR/Recall: 76.70%\n",
      "TNR: 88.62%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from partition_tests import PartitionTester\n",
    "\n",
    "tester = PartitionTester(\"../data/synth_data_for_training.csv\")\n",
    "tester.run(\"model_2.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc368c5f",
   "metadata": {},
   "source": [
    "### Testing Bad Model on Metamorphic Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb403c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\dsait\\Y1\\Q2\\SETAIS\\assignment-1-testing\\subgroup_1\\metamorphic_tests.py:26: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_raw = pd.read_csv(self.DATA_PATH, header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Metamorphic Tests ===\n",
      "\n",
      "Original accuracy: 0.863995782814971\n",
      "\n",
      "--- Gender Flip Test ---\n",
      "Accuracy after flip: 0.8621507643647865\n",
      "Number of changed predictions: 13\n",
      "Fraction changed: 0.34%\n",
      "Changed indices: [151, 581, 745, 811, 1758, 1941, 1961, 2440, 2446, 2676, 2884, 3002, 3021]\n",
      "\n",
      "--- Neighborhood Flip Test ---\n",
      "Accuracy after flip: 0.7923036373220875\n",
      "Number of changed predictions: 354\n",
      "Fraction changed: 9.33%\n",
      "Changed indices: [6, 36, 47, 64, 73, 75, 80, 118, 131, 136, 162, 165, 191, 204, 207, 219, 221, 230, 241, 279, 284, 289, 298, 311, 314, 321, 328, 346, 367, 389, 391, 407, 408, 415, 419, 430, 434, 440, 441, 475, 508, 525, 540, 555, 566, 576, 577, 594, 626, 646, 670, 671, 684, 696, 700, 703, 708, 725, 728, 739, 744, 745, 750, 754, 758, 769, 811, 813, 832, 835, 842, 848, 859, 881, 890, 894, 905, 934, 943, 1006, 1019, 1033, 1046, 1050, 1074, 1076, 1083, 1084, 1094, 1106, 1115, 1124, 1152, 1171, 1172, 1188, 1215, 1218, 1234, 1236, 1270, 1300, 1308, 1310, 1319, 1323, 1349, 1350, 1373, 1377, 1384, 1395, 1403, 1404, 1411, 1440, 1441, 1446, 1450, 1480, 1494, 1497, 1500, 1502, 1515, 1517, 1520, 1522, 1534, 1539, 1544, 1548, 1551, 1556, 1576, 1584, 1640, 1660, 1673, 1685, 1697, 1707, 1719, 1720, 1728, 1738, 1747, 1749, 1758, 1773, 1784, 1793, 1798, 1801, 1804, 1806, 1810, 1811, 1827, 1838, 1842, 1851, 1862, 1863, 1888, 1898, 1911, 1916, 1920, 1941, 1943, 1945, 1961, 1964, 1966, 1974, 1999, 2024, 2040, 2043, 2044, 2055, 2057, 2062, 2065, 2072, 2086, 2108, 2109, 2123, 2161, 2184, 2187, 2198, 2233, 2235, 2249, 2257, 2261, 2280, 2288, 2292, 2294, 2298, 2299, 2306, 2332, 2336, 2369, 2411, 2438, 2440, 2454, 2458, 2489, 2490, 2492, 2498, 2506, 2515, 2516, 2522, 2538, 2550, 2568, 2581, 2591, 2624, 2633, 2641, 2645, 2683, 2696, 2697, 2699, 2706, 2708, 2713, 2725, 2726, 2727, 2752, 2755, 2757, 2764, 2765, 2766, 2771, 2798, 2851, 2870, 2889, 2900, 2904, 2906, 2922, 2930, 2931, 2940, 2956, 2969, 2988, 2989, 2994, 3002, 3018, 3021, 3023, 3030, 3035, 3037, 3052, 3059, 3074, 3107, 3117, 3129, 3130, 3131, 3143, 3157, 3166, 3167, 3176, 3179, 3196, 3216, 3218, 3227, 3243, 3257, 3258, 3266, 3267, 3269, 3278, 3283, 3301, 3309, 3310, 3316, 3320, 3321, 3335, 3336, 3344, 3363, 3373, 3378, 3381, 3395, 3413, 3436, 3437, 3438, 3452, 3466, 3468, 3485, 3487, 3514, 3517, 3535, 3549, 3559, 3595, 3598, 3599, 3604, 3608, 3609, 3627, 3628, 3631, 3641, 3664, 3667, 3668, 3671, 3675, 3677, 3679, 3684, 3686, 3697, 3700, 3704, 3708, 3712, 3737, 3751, 3761, 3780, 3785]\n",
      "\n",
      "--- Offset Relationship Test ---\n",
      "Accuracy after flip: 0.7923036373220875\n",
      "Number of changed predictions: 354\n",
      "Fraction changed: 9.33%\n",
      "Changed indices: [6, 36, 47, 64, 73, 75, 80, 118, 131, 136, 162, 165, 191, 204, 207, 219, 221, 230, 241, 279, 284, 289, 298, 311, 314, 321, 328, 346, 367, 389, 391, 407, 408, 415, 419, 430, 434, 440, 441, 475, 508, 525, 540, 555, 566, 576, 577, 594, 626, 646, 670, 671, 684, 696, 700, 703, 708, 725, 728, 739, 744, 745, 750, 754, 758, 769, 811, 813, 832, 835, 842, 848, 859, 881, 890, 894, 905, 934, 943, 1006, 1019, 1033, 1046, 1050, 1074, 1076, 1083, 1084, 1094, 1106, 1115, 1124, 1152, 1171, 1172, 1188, 1215, 1218, 1234, 1236, 1270, 1300, 1308, 1310, 1319, 1323, 1349, 1350, 1373, 1377, 1384, 1395, 1403, 1404, 1411, 1440, 1441, 1446, 1450, 1480, 1494, 1497, 1500, 1502, 1515, 1517, 1520, 1522, 1534, 1539, 1544, 1548, 1551, 1556, 1576, 1584, 1640, 1660, 1673, 1685, 1697, 1707, 1719, 1720, 1728, 1738, 1747, 1749, 1758, 1773, 1784, 1793, 1798, 1801, 1804, 1806, 1810, 1811, 1827, 1838, 1842, 1851, 1862, 1863, 1888, 1898, 1911, 1916, 1920, 1941, 1943, 1945, 1961, 1964, 1966, 1974, 1999, 2024, 2040, 2043, 2044, 2055, 2057, 2062, 2065, 2072, 2086, 2108, 2109, 2123, 2161, 2184, 2187, 2198, 2233, 2235, 2249, 2257, 2261, 2280, 2288, 2292, 2294, 2298, 2299, 2306, 2332, 2336, 2369, 2411, 2438, 2440, 2454, 2458, 2489, 2490, 2492, 2498, 2506, 2515, 2516, 2522, 2538, 2550, 2568, 2581, 2591, 2624, 2633, 2641, 2645, 2683, 2696, 2697, 2699, 2706, 2708, 2713, 2725, 2726, 2727, 2752, 2755, 2757, 2764, 2765, 2766, 2771, 2798, 2851, 2870, 2889, 2900, 2904, 2906, 2922, 2930, 2931, 2940, 2956, 2969, 2988, 2989, 2994, 3002, 3018, 3021, 3023, 3030, 3035, 3037, 3052, 3059, 3074, 3107, 3117, 3129, 3130, 3131, 3143, 3157, 3166, 3167, 3176, 3179, 3196, 3216, 3218, 3227, 3243, 3257, 3258, 3266, 3267, 3269, 3278, 3283, 3301, 3309, 3310, 3316, 3320, 3321, 3335, 3336, 3344, 3363, 3373, 3378, 3381, 3395, 3413, 3436, 3437, 3438, 3452, 3466, 3468, 3485, 3487, 3514, 3517, 3535, 3549, 3559, 3595, 3598, 3599, 3604, 3608, 3609, 3627, 3628, 3631, 3641, 3664, 3667, 3668, 3671, 3675, 3677, 3679, 3684, 3686, 3697, 3700, 3704, 3708, 3712, 3737, 3751, 3761, 3780, 3785]\n",
      "\n",
      "--- Flip Language Test ---\n",
      "Accuracy after flip: 0.8563521349499209\n",
      "Number of changed predictions: 51\n",
      "Fraction changed: 1.34%\n",
      "Changed indices: [80, 136, 219, 230, 389, 391, 415, 456, 508, 581, 696, 745, 1002, 1046, 1076, 1171, 1236, 1308, 1340, 1349, 1373, 1404, 1500, 1534, 1738, 1806, 1838, 2065, 2332, 2440, 2454, 2755, 2771, 2870, 2906, 2926, 3002, 3021, 3023, 3030, 3107, 3179, 3227, 3257, 3378, 3437, 3598, 3684, 3712, 3730, 3737]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "seed = random.randint(1, 100)\n",
    "tester = MetamorphicTester(data_path=\"../data/synth_data_for_training.csv\", seed=seed)\n",
    "tester.run(\"model_2.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c354f49a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0951cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
